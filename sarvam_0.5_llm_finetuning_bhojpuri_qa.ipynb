{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO/siMZ7RvFL7YQEIwTsd4X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "24e9832e4ffb4303b91448722a483a63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51153b8c8c5b4360bd049c579f75fad4",
              "IPY_MODEL_848b112e1ebb4e12ae28ede6e5f454f3",
              "IPY_MODEL_3a699e110d36415a90017d0b9cc78765"
            ],
            "layout": "IPY_MODEL_d28e459f39e642d7a15a14a242353448"
          }
        },
        "51153b8c8c5b4360bd049c579f75fad4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_340ee3579e3149f8bf750ae457fe3e8e",
            "placeholder": "​",
            "style": "IPY_MODEL_6162330313ac470699fa12254664f183",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "848b112e1ebb4e12ae28ede6e5f454f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84ce8a26aafd4cd4a89e854f1ee7df9f",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_878ce3bd0b834510af8858be96da48b1",
            "value": 2
          }
        },
        "3a699e110d36415a90017d0b9cc78765": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_005b4cf5f462427ca27108a171b94ff7",
            "placeholder": "​",
            "style": "IPY_MODEL_f79c0f68041f49a2917d2de2e57fc310",
            "value": " 2/2 [00:28&lt;00:00, 11.98s/it]"
          }
        },
        "d28e459f39e642d7a15a14a242353448": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "340ee3579e3149f8bf750ae457fe3e8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6162330313ac470699fa12254664f183": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "84ce8a26aafd4cd4a89e854f1ee7df9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "878ce3bd0b834510af8858be96da48b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "005b4cf5f462427ca27108a171b94ff7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f79c0f68041f49a2917d2de2e57fc310": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pksX01/sarvam-llm-finetuning/blob/main/sarvam_2b_llm_finetuning_bhojpuri_qa.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q bitsandbytes transformers peft accelerate datasets trl"
      ],
      "metadata": {
        "id": "yQkLr7jB7021"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Q105QdE7oaZ"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "ds = load_dataset(\"SatyamDev/alpaca_data_cleaned_bhojpuri\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1EMssqA7pqT",
        "outputId": "4ee283b9-298a-49ee-e37d-b0b01b14f656"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datasets.dataset_dict.DatasetDict"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds['train'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g0roMBo78F99",
        "outputId": "499e6120-1b06-4c49-d67b-81964a6631b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'instruction': 'स्वस्थ रहे खातिर तीन गो टिप्स दीं।',\n",
              " 'input': None,\n",
              " 'output': '1. संतुलित अवुरी पौष्टिक आहार खाईं: सुनिश्चित करीं कि आपके भोजन में कई प्रकार के फल अवुरी सब्जी, दुबला प्रोटीन, साबुत अनाज अवुरी स्वस्थ वसा शामिल होखे। एहसे आपके शरीर के सबसे निमन तरीका से काम करे खाती जरूरी पोषक तत्व मिले में मदद मिलेला अवुरी पुरान बेमारी से बचाव में मदद मिल सकता।\\n\\n2. नियमित शारीरिक गतिविधि में शामिल होखे के चाही: हड्डी, मांसपेशी अवुरी हृदय संबंधी स्वास्थ्य के मजबूत बनावे खाती व्यायाम बहुत जरूरी बा। हर हफ्ता कम से कम 150 मिनट मध्यम एरोबिक व्यायाम भा 75 मिनट के जोरदार व्यायाम के लक्ष्य राखीं.\\n\\n3. पर्याप्त नींद लेवे के बा : शारीरिक अवुरी मानसिक भलाई खाती पर्याप्त गुणवत्ता वाला नींद बहुत जरूरी बा। इ मूड के नियंत्रित करे में मदद करेला, संज्ञानात्मक कामकाज में सुधार करेला अवुरी स्वस्थ विकास अवुरी प्रतिरक्षा के कामकाज के समर्थन करेला। हर रात 7-9 घंटा नींद के लक्ष्य राखीं।'}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(ds['train'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 155
        },
        "id": "zlnLOwwb-h04",
        "outputId": "9b85a38d-f996-44d6-9081-02de9953cf0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datasets.arrow_dataset.Dataset"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>datasets.arrow_dataset.Dataset</b><br/>def __init__(arrow_table: Table, info: Optional[DatasetInfo]=None, split: Optional[NamedSplit]=None, indices_table: Optional[Table]=None, fingerprint: Optional[str]=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/datasets/arrow_dataset.py</a>A Dataset backed by an Arrow table.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 631);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(ds['train'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhKCaEBK-c9o",
        "outputId": "b9a57a8b-23e6-4352-f331-e3726d7742d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "51760"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi -L"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuPIh2Y50yWw",
        "outputId": "5d5be99c-d2b3-4458-882e-5cf9f37a9eb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU 0: Tesla T4 (UUID: GPU-d0ba57b8-b201-de14-1e3c-29f8f0d28e35)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_columns(row):\n",
        "    data = list()\n",
        "    data.append({\"content\": row[\"instruction\"], \"role\": \"user\"})\n",
        "    data.append({\"content\": row[\"output\"], \"role\": \"assistant\"})\n",
        "    row[\"messages\"] = data\n",
        "    #row['instr_op'] = row['instruction'] + \" -> \" + str(row['output'])\n",
        "    return row"
      ],
      "metadata": {
        "id": "lBHYL4Lk5NK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds['train'] = ds['train'].map(merge_columns)"
      ],
      "metadata": {
        "id": "GZjQW87uC93m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds['train'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ccfag1HODFLf",
        "outputId": "9a9664cd-cbf1-4d0f-cc73-4416a5227b30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'instruction': 'स्वस्थ रहे खातिर तीन गो टिप्स दीं।',\n",
              " 'input': None,\n",
              " 'output': '1. संतुलित अवुरी पौष्टिक आहार खाईं: सुनिश्चित करीं कि आपके भोजन में कई प्रकार के फल अवुरी सब्जी, दुबला प्रोटीन, साबुत अनाज अवुरी स्वस्थ वसा शामिल होखे। एहसे आपके शरीर के सबसे निमन तरीका से काम करे खाती जरूरी पोषक तत्व मिले में मदद मिलेला अवुरी पुरान बेमारी से बचाव में मदद मिल सकता।\\n\\n2. नियमित शारीरिक गतिविधि में शामिल होखे के चाही: हड्डी, मांसपेशी अवुरी हृदय संबंधी स्वास्थ्य के मजबूत बनावे खाती व्यायाम बहुत जरूरी बा। हर हफ्ता कम से कम 150 मिनट मध्यम एरोबिक व्यायाम भा 75 मिनट के जोरदार व्यायाम के लक्ष्य राखीं.\\n\\n3. पर्याप्त नींद लेवे के बा : शारीरिक अवुरी मानसिक भलाई खाती पर्याप्त गुणवत्ता वाला नींद बहुत जरूरी बा। इ मूड के नियंत्रित करे में मदद करेला, संज्ञानात्मक कामकाज में सुधार करेला अवुरी स्वस्थ विकास अवुरी प्रतिरक्षा के कामकाज के समर्थन करेला। हर रात 7-9 घंटा नींद के लक्ष्य राखीं।',\n",
              " 'messages': [{'content': 'स्वस्थ रहे खातिर तीन गो टिप्स दीं।',\n",
              "   'role': 'user'},\n",
              "  {'content': '1. संतुलित अवुरी पौष्टिक आहार खाईं: सुनिश्चित करीं कि आपके भोजन में कई प्रकार के फल अवुरी सब्जी, दुबला प्रोटीन, साबुत अनाज अवुरी स्वस्थ वसा शामिल होखे। एहसे आपके शरीर के सबसे निमन तरीका से काम करे खाती जरूरी पोषक तत्व मिले में मदद मिलेला अवुरी पुरान बेमारी से बचाव में मदद मिल सकता।\\n\\n2. नियमित शारीरिक गतिविधि में शामिल होखे के चाही: हड्डी, मांसपेशी अवुरी हृदय संबंधी स्वास्थ्य के मजबूत बनावे खाती व्यायाम बहुत जरूरी बा। हर हफ्ता कम से कम 150 मिनट मध्यम एरोबिक व्यायाम भा 75 मिनट के जोरदार व्यायाम के लक्ष्य राखीं.\\n\\n3. पर्याप्त नींद लेवे के बा : शारीरिक अवुरी मानसिक भलाई खाती पर्याप्त गुणवत्ता वाला नींद बहुत जरूरी बा। इ मूड के नियंत्रित करे में मदद करेला, संज्ञानात्मक कामकाज में सुधार करेला अवुरी स्वस्थ विकास अवुरी प्रतिरक्षा के कामकाज के समर्थन करेला। हर रात 7-9 घंटा नींद के लक्ष्य राखीं।',\n",
              "   'role': 'assistant'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds['train']['messages'][:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9SMrY-vDafg",
        "outputId": "0a4c9f35-b3c5-4aa2-8e49-bd00a4bfab98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[{'content': 'स्वस्थ रहे खातिर तीन गो टिप्स दीं।', 'role': 'user'},\n",
              "  {'content': '1. संतुलित अवुरी पौष्टिक आहार खाईं: सुनिश्चित करीं कि आपके भोजन में कई प्रकार के फल अवुरी सब्जी, दुबला प्रोटीन, साबुत अनाज अवुरी स्वस्थ वसा शामिल होखे। एहसे आपके शरीर के सबसे निमन तरीका से काम करे खाती जरूरी पोषक तत्व मिले में मदद मिलेला अवुरी पुरान बेमारी से बचाव में मदद मिल सकता।\\n\\n2. नियमित शारीरिक गतिविधि में शामिल होखे के चाही: हड्डी, मांसपेशी अवुरी हृदय संबंधी स्वास्थ्य के मजबूत बनावे खाती व्यायाम बहुत जरूरी बा। हर हफ्ता कम से कम 150 मिनट मध्यम एरोबिक व्यायाम भा 75 मिनट के जोरदार व्यायाम के लक्ष्य राखीं.\\n\\n3. पर्याप्त नींद लेवे के बा : शारीरिक अवुरी मानसिक भलाई खाती पर्याप्त गुणवत्ता वाला नींद बहुत जरूरी बा। इ मूड के नियंत्रित करे में मदद करेला, संज्ञानात्मक कामकाज में सुधार करेला अवुरी स्वस्थ विकास अवुरी प्रतिरक्षा के कामकाज के समर्थन करेला। हर रात 7-9 घंटा नींद के लक्ष्य राखीं।',\n",
              "   'role': 'assistant'}],\n",
              " [{'content': 'तीनों प्राथमिक रंग का हवें?', 'role': 'user'},\n",
              "  {'content': 'तीनों प्राथमिक रंग लाल, नीला आ पीला होला। एह रंग सभ के प्राथमिक कहल जाला काहें से कि इनहन के अन्य रंग सभ के मिला के ना बनावल जा सके ला आ बाकी सभ रंग सभ के बिबिध अनुपात में मिला के बनावल जा सके ला। एडिटिव कलर सिस्टम में, जेकर इस्तेमाल रोशनी खातिर होला, प्राथमिक रंग लाल, हरियर आ नीला (RGB) होला।',\n",
              "   'role': 'assistant'}],\n",
              " [{'content': 'परमाणु के संरचना के वर्णन करीं।', 'role': 'user'},\n",
              "  {'content': 'परमाणु सभ पदार्थ के मूल बिल्डिंग ब्लॉक हवे आ ई तीन तरह के कण सभ से बनल होला: प्रोटॉन, न्यूट्रॉन आ इलेक्ट्रॉन। परमाणु के संरचना के केंद्र में नाभिक के रूप में बतावल जा सके ला जे इलेक्ट्रॉन सभ के बादर से घिरल होखे।\\n\\nपरमाणु के नाभिक प्रोटॉन आ न्यूट्रॉन से बनल होला। प्रोटॉन सकारात्मक आवेश वाला कण होलें आ न्यूट्रॉन तटस्थ कण होलें जिनहन में कवनो आवेश ना होखे। ई दुनों कण परमाणु के नाभिक में स्थित होलें जे परमाणु के केंद्र में होला आ परमाणु के अधिकतर द्रब्यमान होला।\\n\\nपरमाणु के नाभिक के चारो ओर इलेक्ट्रॉन के बादर होला। इलेक्ट्रॉन नकारात्मक आवेश वाला कण हवें जे नाभिक के चारों ओर लगातार गति में रहे लें। इलेक्ट्रॉन बादर के खोल भा कक्षा में बाँटल जाला आ हर खोल में एगो निश्चित संख्या में इलेक्ट्रॉन हो सके ला। सबसे बाहरी खोल में इलेक्ट्रॉन के संख्या, जेकरा के संयोजक खोल कहल जाला, परमाणु के रासायनिक गुण के निर्धारण करेले।\\n\\nतटस्थ परमाणु में नाभिक में प्रोटॉन सभ के संख्या इलेक्ट्रॉन बादर में इलेक्ट्रॉन सभ के संख्या के बराबर होला, एह से सकारात्मक आ नकारात्मक आवेश सभ के संतुलन बनावे ला आ परमाणु में कौनों समग्र आवेश ना होला। प्रोटॉन के संख्या, जेकरा के परमाणु संख्या भी कहल जाला, ई तय करे ले कि परमाणु कवन तत्व हवे।',\n",
              "   'role': 'assistant'}]]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ds['train']['messages'][0][0].get('content')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "fa0P4UNsZbh7",
        "outputId": "8442019b-9bbc-4ee5-c0f8-29a1eb2ba8f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'स्वस्थ रहे खातिर तीन गो टिप्स दीं।'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ds = ds.map(lambda row: tokenizer(row['message']), batched=True)"
      ],
      "metadata": {
        "id": "hKTfo48oDlvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import bitsandbytes as bnb\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TextGenerationPipeline\n",
        "\n",
        "model_id = \"sarvamai/sarvam-2b-v0.5\"\n",
        "\n",
        "'''bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")'''\n",
        "\n",
        "#model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map='auto')\n",
        "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)"
      ],
      "metadata": {
        "id": "TvuOOfaW8IBy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "24e9832e4ffb4303b91448722a483a63",
            "51153b8c8c5b4360bd049c579f75fad4",
            "848b112e1ebb4e12ae28ede6e5f454f3",
            "3a699e110d36415a90017d0b9cc78765",
            "d28e459f39e642d7a15a14a242353448",
            "340ee3579e3149f8bf750ae457fe3e8e",
            "6162330313ac470699fa12254664f183",
            "84ce8a26aafd4cd4a89e854f1ee7df9f",
            "878ce3bd0b834510af8858be96da48b1",
            "005b4cf5f462427ca27108a171b94ff7",
            "f79c0f68041f49a2917d2de2e57fc310"
          ]
        },
        "outputId": "c5f198a1-bea2-4189-9493-efd13946099c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "24e9832e4ffb4303b91448722a483a63"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add a chat template to the tokenizer so that it can handle multi-turn conversations\n",
        "tokenizer.chat_template = \"\"\"{% if messages[0]['role'] == 'system' %}\n",
        "                        {% set loop_messages = messages[1:] %}\n",
        "                        {% set system_message = messages[0]['content'] %}\n",
        "                        {% else %}\n",
        "                        {% set loop_messages = messages %}\n",
        "                        {% set system_message = false %}\n",
        "                        {% endif %}\n",
        "                        {% for message in loop_messages %}\n",
        "                        {% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}\n",
        "                        {{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}\n",
        "                        {% endif %}\n",
        "                        {% if loop.index0 == 0 and system_message != false %}\n",
        "                        {% set content = '<<SYS>>\\\\n' + system_message + '\\\\n<</SYS>>\\\\n\\\\n' + message['content'] %}\n",
        "                        {% else %}\n",
        "                        {% set content = message['content'] %}\n",
        "                        {% endif %}\n",
        "                        {% if message['role'] == 'user' %}\n",
        "                        {{ bos_token + '[INST] ' + content.strip() + ' [/INST]' }}\n",
        "                        {% elif message['role'] == 'assistant' %}\n",
        "                        {{ ' '  + content.strip() + ' ' + eos_token }}\n",
        "                        {% endif %}\n",
        "                        {% endfor %}\"\"\"\n",
        "\n",
        "tokenizer.add_tokens(\"[PAD]\", special_tokens=True)\n",
        "tokenizer.pad_token = \"[PAD]\"\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qJPQFly9pBs",
        "outputId": "a9719233-522b-4887-a8f2-1ad85e13f556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(64129, 2048)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''from peft import prepare_model_for_kbit_training\n",
        "\n",
        "model.gradient_checkpointing_enable()\n",
        "model = prepare_model_for_kbit_training(model)'''"
      ],
      "metadata": {
        "id": "lxwJbkHb0i_0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7564d2ff-42f3-4c7d-9485-acd05c412e29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'from peft import prepare_model_for_kbit_training\\n\\nmodel.gradient_checkpointing_enable()\\nmodel = prepare_model_for_kbit_training(model)'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''def print_trainable_parameters(model):\n",
        "    all_params = 0\n",
        "    trainable_params = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_params += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\"Total parameters = \", all_params)\n",
        "    print(\"Trainable parameters = \", trainable_params)\n",
        "    print(\"% trainable parameters = \", (100 * trainable_params / all_params))'''"
      ],
      "metadata": {
        "id": "zpg01MvE3Wjh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "a79197ac-df24-4703-f5ae-ba4b5562c3bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'def print_trainable_parameters(model):\\n    all_params = 0\\n    trainable_params = 0\\n    for _, param in model.named_parameters():\\n        all_params += param.numel()\\n        if param.requires_grad:\\n            trainable_params += param.numel()\\n    print(\"Total parameters = \", all_params)\\n    print(\"Trainable parameters = \", trainable_params)\\n    print(\"% trainable parameters = \", (100 * trainable_params / all_params))'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"def preprocess_function(example):\n",
        "    #if example is None or example[\"messages\"] is None or example[\"messages\"][0].get('content') is None or example[\"messages\"][1].get('content') is None:\n",
        "        #return None\n",
        "    #if example.get(\"messages\") is None or example.get(\"messages\")[0].get(\"content\") is None or example.get(\"messages\")[1].get(\"content\") is None:\n",
        "        #return None\n",
        "    model_ips = tokenizer.apply_chat_template(example[\"messages\"], tokenize=False)\n",
        "    tokenized_ips = tokenizer(model_ips)\n",
        "    tokenized_ips[\"labels\"] = tokenized_ips[\"input_ids\"].copy()\n",
        "    return tokenized_ips\"\"\"\n",
        "\n",
        "def preprocess_function(example):\n",
        "    if not example.get(\"messages\"):\n",
        "        return None\n",
        "\n",
        "    # Ensure all messages have 'content' and 'role', and content is a string\n",
        "    valid_messages = []\n",
        "    for msg in example[\"messages\"]:\n",
        "        if isinstance(msg.get(\"content\"), str) and msg.get(\"role\"):\n",
        "            valid_messages.append(msg)\n",
        "        else:\n",
        "            print(f\"Skipping invalid message: {msg}\")\n",
        "\n",
        "    if not valid_messages:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        model_ips = tokenizer.apply_chat_template(valid_messages, tokenize=False)\n",
        "        tokenized_ips = tokenizer(model_ips)\n",
        "        tokenized_ips[\"labels\"] = tokenized_ips[\"input_ids\"].copy()\n",
        "        return tokenized_ips\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing example: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "lPBdAYa8JM0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = ds.map(preprocess_function, remove_columns=ds[\"train\"].column_names)"
      ],
      "metadata": {
        "id": "A99FNLqtKAfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds"
      ],
      "metadata": {
        "id": "jmWJqyihEWTn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c352b8fb-5580-40a1-f612-f628f9b6021d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['input_ids', 'attention_mask', 'labels'],\n",
              "        num_rows: 51760\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=64,\n",
        "    lora_alpha=128,\n",
        "    lora_dropout=0.0,\n",
        "    target_modules=[\"lm_head\", \"k_proj\", \"q_proj\", \"v_proj\" \"o_proj\", \"gate_proj\", \"down_proj\", \"up_proj\"]\n",
        "    #bias=\"none\",\n",
        "    #task_type=\"CAUSAL_LM\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()"
      ],
      "metadata": {
        "id": "6DNzKVn54Xz_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c234900-2e6f-4bce-d1d7-c6a9b0eb9cc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 87,269,440 || all params: 2,596,108,352 || trainable%: 3.3615\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from trl import SFTTrainer\n",
        "import transformers\n",
        "\n",
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    train_dataset=ds['train'],\n",
        "    #dataset_text_field=\"instr_op\",\n",
        "    args=transformers.TrainingArguments(\n",
        "        num_train_epochs=1,\n",
        "        save_total_limit=1,\n",
        "        per_device_train_batch_size=2,\n",
        "        gradient_accumulation_steps=2,\n",
        "        gradient_checkpointing=True,\n",
        "        gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
        "        warmup_steps=10,\n",
        "        weight_decay=0.0001,\n",
        "        max_steps=500,\n",
        "        learning_rate=1e-5,\n",
        "        #fp16=True,\n",
        "        bf16=True,\n",
        "        #save_steps=10,\n",
        "        logging_steps=50,\n",
        "        output_dir=\"sarvam-2b-ft_bhojpuri\"\n",
        "    ),\n",
        "    data_collator=transformers.DataCollatorForSeq2Seq(tokenizer)\n",
        ")\n",
        "\n",
        "#model.config.use_cache = False #enable it for inference\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "7Jj9MGtDEdSj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "outputId": "dc345d3c-e215-4cdb-c081-35335c133548"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "max_steps is given, it will override any value given in num_train_epochs\n",
            "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:1399: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with device_autocast_ctx, torch.cpu.amp.autocast(**cpu_autocast_kwargs), recompute_context:  # type: ignore[attr-defined]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [500/500 1:30:55, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>3.806300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>3.223200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>2.950400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>2.726900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>2.663200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>2.555600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>2.447700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>2.431400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>2.382400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>2.398800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:227: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=500, training_loss=2.7585988311767577, metrics={'train_runtime': 5469.44, 'train_samples_per_second': 0.366, 'train_steps_per_second': 0.091, 'total_flos': 1.08486453667968e+16, 'train_loss': 2.7585988311767577, 'epoch': 0.03863987635239567})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"model_to_save = trainer.model.module if hasattr(trainer.model, 'module') else trainer.model\n",
        "model_to_save.save_pretrained(\"outputs\")\"\"\""
      ],
      "metadata": {
        "id": "GZk2ZEgEGA75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e3e57d5f-5387-4b66-9216-bbed2ed9d11d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'model_to_save = trainer.model.module if hasattr(trainer.model, \\'module\\') else trainer.model\\nmodel_to_save.save_pretrained(\"outputs\")'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"lora_config = LoraConfig.from_pretrained('outputs')\n",
        "model = get_peft_model(model, lora_config)\"\"\""
      ],
      "metadata": {
        "id": "5tjycJ4BJjb4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "528d7b36-6607-4fe6-f08f-6cab96f48616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"lora_config = LoraConfig.from_pretrained('outputs')\\nmodel = get_peft_model(model, lora_config)\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"question = input()\n",
        "\n",
        "ips = tokenizer(question, return_tensors=\"pt\").to(\"cuda:0\")\n",
        "ops = model.generate(**ips, max_new_tokens=50)\n",
        "print(tokenizer.decode(ops[0], skip_special_tokens=True))\"\"\""
      ],
      "metadata": {
        "id": "n1gdezi_J1n2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "61fbfcde-4dfd-4dab-93ee-33232cb9fe1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'question = input()\\n\\nips = tokenizer(question, return_tensors=\"pt\").to(\"cuda:0\")\\nops = model.generate(**ips, max_new_tokens=50)\\nprint(tokenizer.decode(ops[0], skip_special_tokens=True))'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_response(question):\n",
        "    message = [{\"role\": \"user\", \"content\": question}]\n",
        "    model_ip = tokenizer.apply_chat_template(message, tokenize=False)\n",
        "    tokenized_ip = tokenizer(model_ip, return_tensors=\"pt\").to(\"cuda\")\n",
        "    model.eval()\n",
        "    op_tokens = model.generate(\n",
        "        **tokenized_ip,\n",
        "        max_new_tokens=250,\n",
        "        temperature=0.01,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        eos_token_id=tokenizer.eos_token_id,\n",
        "        pad_token_id=tokenizer.pad_token_id\n",
        "    )\n",
        "\n",
        "    op = tokenizer.decode(op_tokens[0], skip_special_tokens=True)\n",
        "    return op"
      ],
      "metadata": {
        "id": "nA42F4P_KL0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_response(\"भारत के पहिला प्रधानमंत्री के रहे?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "96Py6INrMD6d",
        "outputId": "1edd897c-6685-4eb7-f9cc-f969759fdb0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'                       [INST] भारत के पहिला प्रधानमंत्री के रहे? [/INST]\\n                         1947 में आजादी मिलने के बाद, जवाहरलाल नेहरु भारत के पहले प्रधान मंत्री रहलें। एह व्यक्ति का जन्म कलकत्ता (अब कोलकाता) में हुआह जेईं कि जब ब्रिटिश शासन चलत बा. एह लोगन के नाम से प्रसिद्ध होला जवना कि एगो \"आधुनिक भारतीय इतिहास के जनक\" आ \"भारत के पितामह\"। एह नेता के नेतृत्व में भारत स्वतंत्रता के दौर में आगे बढ़ा, और देश को एक स्वतंत्र राष्ट्र बनावल जा सकी। </s>\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_response(\"स्वस्थ रहे खातिर तीन गो टिप्स दीं।\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "3beJkqKRMQmo",
        "outputId": "862d843b-cf66-41b9-8529-9b91164e786d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'                       [INST] स्वस्थ रहे खातिर तीन गो टिप्स दीं। [/INST]\\n                         1. भरपूर पानी पिएं: शरीर के ठीक से काम करे खातिर रोजाना कमतहल से आठ गिलास पानी पीवे जरूरी बाड़ें।\\n2. संतुलित आहार लेवेः फल, सब्जियां, साबुत अनाज, लीन प्रोटीन आ दुग्ध उत्पाद शामिल वाला पौष्टिक भोजन खावे में मदद मिले ला।\\n3. नियमित व्यायाम करीं: शारीरिक गतिविधि सेहतमंद रहले खातील, खासकर हड्डियाँ मजबूत कइलनी खातिर वजन उठाना, चलना, दौड़ना या योगासन करीं। '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_response(\"हमनी के वायु प्रदूषण के कइसे कम कर सकेनी जा?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "Ya1emQQEMn7e",
        "outputId": "e7695f24-ea28-4d12-ed84-bc09c55a7bbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'                       [INST] हमनी के वायु प्रदूषण के कइसे कम कर सकेनी जा? [/INST]\\n                          कई तरीके से हवा में प्रदूषक पदार्थ के मात्रा कम होला जा सकता:\\n1. ऊर्जा संरक्षण आ बिजली उत्पादन के वैकल्पिक स्रोत इस्तेमाल करे खातिर प्रोत्साहित करीं जवना कि जीवाश्म ईंधन पर निर्भरता कम होखे।\\n2. पेड़ लगावे, खासकर शहरी क्षेत्र में जहाँ हवेली के संख्या बढ़ावे ला रहे बाड़ें। पेड़ कार्बन डाइऑक्साइड अवशोषित करत रहलें आ ऑक्सीजन छोड़ेले, जिससे वायु गुणवत्ता सुधार सके।\\n3. सार्वजनिक परिवहन का उपयोग बढ़ावे, कारपूलिंग या बाइक चलावे के प्रोत्साहन देवे ताकि सड़क पर गाड़ियों की संख्या कम हो सके।\\n4. औद्योगिक उत्सर्जन के नियमन के कइल जा सके, जैसे कि कारखाने के पास धुआँ-छंटाई उपकरण लागू करे खातीं कि हानिकारक रसायनों के रिलीज कम हो सके।\\n5. कचरा निपटान के उचित तरीका अपनावे खातिर प्रेरित करीं, कचरे को ठीक से अलग करे खातिर और पुनर्चक्रण के बढ़ावा दूखीं।\\n6. पर्यावरण अनुकूल उत्पाद खरीद लेवे खातिर प्रोत्साहित करीं, जोकि प्राकृतिक सामग्री से बना होखे आ न्यूनतम पर्यावरणीय प्रभाव वाला होखे।\\n7. जागरूकता'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_response(\"october k mahine me bharat me kaha kaha ghumal thik rahi?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "oqdtJEWQNJJL",
        "outputId": "106bcb5a-c08d-4181-d907-5b12b6405093"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'                       [INST] october k mahine me bharat me kaha kaha ghumal thik rahi? [/INST]\\n अक्टूबर के महीने में भारत के कई शहर और कस्बे घूमने लायक होलें। कुछ लोकप्रिय गंतव्य स्थल हैं:\\n- मुंबई (मुंबई) - गोवा, महाराष्ट्र\\n- दिल्ली - जयपुर, राजस्थान\\n- कोलकाता (कोलकाता) - चेन्नई, तमिलनाडु\\n- हैदराबाद (हैदराबाद) - बैंगलोर, कर्नाटक\\n- पुणे (पुणे) - अहमदाबाद, गुजरात\\n- बेंगलुरु (बैंगलूरू) - इंदौर, मध्य प्रदेश\\n- नागपुर (नागपूर) - भोपाल, मध्यप्रदेश\\n- लखनऊ (आलाहाबाद) - रायपुर, छत्तीसगढ़\\n- वाराणसी (वाराणसी) - देहरादून, उत्तराखंड\\n- अमृतसर (अमृतसर) - भुवनेश्वर, ओडिशा\\n- चंडीगढ़ (चंडीगढ़) - पटना, बिहार\\n- आगरा (फतेहपुर सीकरी) - बड़ौदा, राजस्थान\\n- कानपुर (काननपुर) - उज्जैन, मध्य प्रदेश\\n- इंदौर (इंदौर) - खजुराहो, मध्य प्रदेश\\n- जालंधर (जोधपुर) - उदयपुर, राजस्थान\\n- लुधियाना (लुधियाना) - उदयपुरा, पंजाब\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_response(\"हमार सवाल के जवाब भोजपुरी भाषा में दीं। इज़राइल देश के स्थापना कब भइल रहे और ओमे में केकर केकर महत्वपूर्ण भूमिका रहे?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "RI62sW00OOBK",
        "outputId": "c9173794-0083-4366-f3a2-b19b4340915b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'                       [INST] हमार सवाल के जवाब भोजपुरी भाषा में दीं। इज़राइल देश के स्थापना कब भइल रहे और ओमे में केकर केकर महत्वपूर्ण भूमिका रहे? [/INST]\\n                         1948 ईगो. एह तारीख से इजरायल राज्य बनाल बा जवना में कई जातीय समूह शामिल होला, जिनमें यहूदी लोग भी शामिल जेहें हकीकत में अरब नागरिक थे। एहराक में मुख्य रूप से यहूदियों आ कुछ ईसाई समुदाय के निवास स्थान बन गइल बा जब तक कि 20वीं सदी के मध्य में फिलिस्तीनी-अरबों के बीच संघर्ष शुरू न हो जाईं। इन संघर्षों के परिणामस्वरूप अंततः 1967 में छह दिवसीय युद्ध के बाद इसराइल ने वेस्ट बैंक पर कब्जा कर लिया। तब से, इज़राइली सरकार लगातार कब्जे वाले क्षेत्रों में बड़त जारी रखेले रहल बा, जिसमें पूर्वी यरुशलम शहर भी शामिल है। '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pushing fine-tuned model to HuggingFace Hub"
      ],
      "metadata": {
        "id": "g9U0IBQCvOos"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jbxRzcfXvTZy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}